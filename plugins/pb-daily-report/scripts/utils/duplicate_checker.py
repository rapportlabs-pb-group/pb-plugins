#!/usr/bin/env python3
"""
Duplicate Checker - PB Daily Report ì¤‘ë³µ ìƒì„± ë°©ì§€

Notionì—ì„œ í•´ë‹¹ ë‚ ì§œì˜ PB Daily Reportê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€
í™•ì¸í•˜ì—¬ ì¤‘ë³µ ìƒì„±ì„ ë°©ì§€í•©ë‹ˆë‹¤.
"""

import json
import sys
import subprocess
import time

def search_existing_pages(date_str, title=None, claude_path="claude"):
    """Notionì—ì„œ í•´ë‹¹ ë‚ ì§œì˜ í˜ì´ì§€ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""

    search_queries = [
        f"PB Daily Report {date_str}",
        f"PB Daily Report - {date_str}",
        date_str
    ]

    if title:
        search_queries.insert(0, title)

    found_pages = []

    for query in search_queries:
        try:
            # Notion ê²€ìƒ‰ ì‹¤í–‰
            cmd = [
                claude_path,
                "-p", f'mcp__notionMCP__notion-searchë¡œ "{query}" ê²€ìƒ‰í•˜ì—¬ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”. query_typeì€ internalë¡œ ì„¤ì •í•˜ì„¸ìš”.',
                "--output-format", "json",
                "--max-turns", "3",
                "--permission-mode", "bypassPermissions",
                "--allowedTools", "mcp__notionMCP"
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

            if result.returncode != 0:
                continue

            # ê²°ê³¼ íŒŒì‹±
            try:
                output = json.loads(result.stdout)
                result_str = output.get("result", "")

                # resultê°€ JSON ë¬¸ìì—´ì¸ ê²½ìš° ë‹¤ì‹œ íŒŒì‹±
                if isinstance(result_str, str) and result_str.strip().startswith('{'):
                    search_results = json.loads(result_str)
                elif isinstance(result_str, dict):
                    search_results = result_str
                else:
                    continue

                # ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
                if "results" in search_results:
                    for item in search_results["results"]:
                        page_title = item.get("title", "")
                        page_id = item.get("id", "")
                        page_url = item.get("url", "")

                        # ë‚ ì§œê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                        if date_str in page_title and "PB Daily Report" in page_title:
                            found_pages.append({
                                "id": page_id,
                                "title": page_title,
                                "url": page_url,
                                "timestamp": item.get("timestamp"),
                                "search_query": query
                            })

            except json.JSONDecodeError:
                continue

        except subprocess.TimeoutExpired:
            print(f"WARNING: ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ - query: {query}")
            continue
        except Exception as e:
            print(f"WARNING: ê²€ìƒ‰ ì‹¤íŒ¨ - query: {query}, error: {e}")
            continue

        # ê²€ìƒ‰ ê°„ ì ì‹œ ëŒ€ê¸°
        time.sleep(1)

    # ì¤‘ë³µ ì œê±° (ê°™ì€ IDì¸ ê²½ìš°)
    unique_pages = {}
    for page in found_pages:
        page_id = page["id"]
        if page_id not in unique_pages:
            unique_pages[page_id] = page

    return list(unique_pages.values())

def check_duplicate_by_date(date_str, title=None):
    """ë‚ ì§œ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë³µ í˜ì´ì§€ í™•ì¸"""

    print(f"ğŸ” ì¤‘ë³µ í˜ì´ì§€ ê²€ìƒ‰ ì¤‘... (ë‚ ì§œ: {date_str})")

    try:
        existing_pages = search_existing_pages(date_str, title)

        if not existing_pages:
            return {
                "has_duplicate": False,
                "message": f"âœ… ì¤‘ë³µ ì—†ìŒ: {date_str} ë‚ ì§œì˜ PB Daily Reportê°€ ì—†ìŠµë‹ˆë‹¤.",
                "date": date_str,
                "search_count": 0
            }

        # ê°€ì¥ ìµœê·¼ í˜ì´ì§€ ì„ íƒ
        latest_page = max(existing_pages, key=lambda x: x.get("timestamp", ""))

        return {
            "has_duplicate": True,
            "message": f"âš ï¸ ì¤‘ë³µ ë°œê²¬: {date_str} ë‚ ì§œì˜ PB Daily Reportê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.",
            "date": date_str,
            "search_count": len(existing_pages),
            "existing_pages": existing_pages,
            "latest_page": latest_page,
            "recommendation": "ê¸°ì¡´ í˜ì´ì§€ ì—…ë°ì´íŠ¸ ë˜ëŠ” ì‹¤í–‰ ê±´ë„ˆë›°ê¸°"
        }

    except Exception as e:
        return {
            "has_duplicate": False,
            "error": True,
            "message": f"âŒ ì¤‘ë³µ ê²€ì‚¬ ì‹¤íŒ¨: {str(e)}",
            "date": date_str,
            "recommendation": "ì•ˆì „ì„ ìœ„í•´ ì‹¤í–‰ ì§„í–‰"
        }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("Usage: python3 duplicate_checker.py <date> [title]")
        print("Example: python3 duplicate_checker.py 2025-09-22 'PB Daily Report - 2025-09-22 (ì›”ìš”ì¼)'")
        sys.exit(1)

    date_str = sys.argv[1]
    title = sys.argv[2] if len(sys.argv) > 2 else None

    # ë‚ ì§œ í˜•ì‹ ê²€ì¦
    try:
        from datetime import datetime
        datetime.strptime(date_str, '%Y-%m-%d')
    except ValueError:
        print(f"âŒ ERROR: ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {date_str} (YYYY-MM-DD í˜•ì‹ í•„ìš”)")
        sys.exit(2)

    # ì¤‘ë³µ ê²€ì‚¬ ì‹¤í–‰
    result = check_duplicate_by_date(date_str, title)

    # ê²°ê³¼ ì¶œë ¥
    print(json.dumps(result, ensure_ascii=False, indent=2))

    # ì¢…ë£Œ ì½”ë“œ ì„¤ì •
    if result.get("has_duplicate", False):
        # ì¤‘ë³µ ë°œê²¬ ì‹œ ì¢…ë£Œ ì½”ë“œ 20
        sys.exit(20)
    elif result.get("error", False):
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì¢…ë£Œ ì½”ë“œ 21
        sys.exit(21)
    else:
        # ì¤‘ë³µ ì—†ìŒ - ì •ìƒ ì§„í–‰
        sys.exit(0)

if __name__ == "__main__":
    main()