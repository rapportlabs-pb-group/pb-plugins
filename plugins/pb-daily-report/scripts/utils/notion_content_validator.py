#!/usr/bin/env python3
"""
Notion Content Validator - PB Daily Report ì™„ì „ì„± ê²€ì¦

MCPì—ì„œ ìƒì„±ëœ ì›ë³¸ ë°ì´í„°ì™€ Notion í˜ì´ì§€ ë‚´ìš©ì„ ë¹„êµí•˜ì—¬
ëª¨ë“  í•„ìˆ˜ ì„¹ì…˜ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.

v2.0 ê°œì„ ì‚¬í•­:
- ë‚ ì§œ ì¼ì¹˜ì„± ê²€ì¦ ì¶”ê°€
- ë¸Œëœë“œ ë°ì´í„° ì™„ì „ì„± ì²´í¬ ê°•í™”
- Top 10 ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€ í™•ì¸
"""

import json
import sys
import re
from datetime import datetime, date
from typing import Dict, List, Set

def extract_mcp_sections(mcp_data: str) -> Set[str]:
    """MCP ì›ë³¸ ë°ì´í„°ì—ì„œ í¬í•¨ëœ ì„¹ì…˜ë“¤ì„ ì¶”ì¶œ"""
    sections = set()

    # JSON íŒŒì‹±
    try:
        data = json.loads(mcp_data)
        report_content = data.get("daily_intelligence_briefing_report", "")
    except:
        print("ERROR: MCP ë°ì´í„° JSON íŒŒì‹± ì‹¤íŒ¨")
        sys.exit(10)

    # í•„ìˆ˜ ì„¹ì…˜ íŒ¨í„´ ê²€ì‚¬
    section_patterns = {
        "brand_snapshots": r"ğŸ“ˆ ë¸Œëœë“œë³„ ìŠ¤ëƒ…ìƒ·|ë¸Œëœë“œë³„.*ìŠ¤ëƒ…ìƒ·",
        "top_performers": r"ğŸš€ Top Performers|Top Performers",
        "urgent_priorities": r"ğŸš¨ Urgent Priorities|Urgent Priorities",
        "action_items": r"ğŸ¯.*Action Items|Today's Action Items",
        "top_10_products": r"ğŸ”¥ Top 10.*ìƒí’ˆ|Top 10.*ê¸‰ì„±ì¥",
        "missed_opportunities": r"ğŸ’¡ Missed Opportunities|Missed Opportunities",
        "required_actions": r"âš ï¸.*ì¡°ì¹˜ê°€ í•„ìš”í•œ|ì¡°ì¹˜ê°€ í•„ìš”í•œ ìƒí’ˆ",
        "detailed_analysis": r"ğŸ“Š ìƒí’ˆë³„ ìƒì„¸.*ë¶„ì„|ìƒí’ˆë³„.*ìƒì„¸.*ë¶„ì„"
    }

    for section_key, pattern in section_patterns.items():
        if re.search(pattern, report_content, re.IGNORECASE):
            sections.add(section_key)

    # ë¸Œëœë“œ ê°œìˆ˜ í™•ì¸ (ìµœì†Œ 8ê°œ ë¸Œëœë“œ í¬í•¨ë˜ì–´ì•¼ í•¨)
    brand_patterns = [
        r"ë…¸ì–´.*GMV", r"ë‹¤ë‚˜ì•¤í˜íƒ€.*GMV", r"ë§ˆì¹˜ë§ˆë¼.*GMV",
        r"ë¸Œì—íŠ¸ì™€.*GMV", r"ì•„ë¥´ì•™.*GMV", r"ì§€ì¬.*GMV",
        r"í¬ì• .*GMV", r"í€¸ì¦ˆì…€ë ‰ì…˜.*GMV"
    ]
    brand_count = sum(1 for pattern in brand_patterns
                     if re.search(pattern, report_content))

    if brand_count >= 7:  # ìµœì†Œ 7ê°œ ë¸Œëœë“œ (í€¸ì¦ˆì…€ë ‰ì…˜ ì œì™¸ ê°€ëŠ¥)
        sections.add("sufficient_brands")

    return sections

def extract_notion_sections(notion_content: str) -> Set[str]:
    """Notion í˜ì´ì§€ ë‚´ìš©ì—ì„œ í¬í•¨ëœ ì„¹ì…˜ë“¤ì„ ì¶”ì¶œ"""
    sections = set()

    # í•„ìˆ˜ ì„¹ì…˜ íŒ¨í„´ ê²€ì‚¬ (Notion ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
    section_patterns = {
        "brand_snapshots": r"ë¸Œëœë“œë³„.*ìŠ¤ëƒ…ìƒ·|ğŸ“ˆ.*ë¸Œëœë“œë³„",
        "top_performers": r"ğŸš€.*Top Performers|Top Performers",
        "urgent_priorities": r"ğŸš¨.*Urgent Priorities|Urgent Priorities",
        "action_items": r"ğŸ¯.*Action Items|Today's Action Items",
        "top_10_products": r"ğŸ”¥.*Top 10.*ìƒí’ˆ|Top 10.*ê¸‰ì„±ì¥",
        "missed_opportunities": r"ğŸ’¡.*Missed Opportunities|Missed Opportunities",
        "required_actions": r"âš ï¸.*ì¡°ì¹˜ê°€ í•„ìš”í•œ|ì¡°ì¹˜ê°€ í•„ìš”í•œ ìƒí’ˆ",
        "detailed_analysis": r"ğŸ“Š.*ìƒí’ˆë³„ ìƒì„¸.*ë¶„ì„|ìƒí’ˆë³„.*ìƒì„¸.*ë¶„ì„"
    }

    for section_key, pattern in section_patterns.items():
        if re.search(pattern, notion_content, re.IGNORECASE):
            sections.add(section_key)

    # ë¸Œëœë“œ ê°œìˆ˜ í™•ì¸
    brand_patterns = [
        r"\*\*ë…¸ì–´\*\*", r"\*\*ë‹¤ë‚˜ì•¤í˜íƒ€\*\*", r"\*\*ë§ˆì¹˜ë§ˆë¼\*\*",
        r"\*\*ë¸Œì—íŠ¸ì™€\*\*", r"\*\*ì•„ë¥´ì•™\*\*", r"\*\*ì§€ì¬\*\*",
        r"\*\*í¬ì• \*\*", r"\*\*í€¸ì¦ˆì…€ë ‰ì…˜\*\*"
    ]
    brand_count = sum(1 for pattern in brand_patterns
                     if re.search(pattern, notion_content))

    if brand_count >= 7:
        sections.add("sufficient_brands")

    return sections

def extract_date_from_content(content: str) -> List[str]:
    """ì»¨í…ì¸ ì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ"""
    date_patterns = [
        r'(\d{4}-\d{2}-\d{2})',  # YYYY-MM-DD
        r'(\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼)',  # YYYYë…„ MMì›” DDì¼
        r'(\d{1,2}ì›”\s*\d{1,2}ì¼)',  # MMì›” DDì¼
        r'(ì›”ìš”ì¼|í™”ìš”ì¼|ìˆ˜ìš”ì¼|ëª©ìš”ì¼|ê¸ˆìš”ì¼|í† ìš”ì¼|ì¼ìš”ì¼)',  # ìš”ì¼
    ]

    found_dates = []
    for pattern in date_patterns:
        matches = re.findall(pattern, content)
        found_dates.extend(matches)

    return found_dates

def validate_date_consistency(mcp_data: str, notion_content: str, expected_date: str = None) -> Dict:
    """MCP ë°ì´í„°ì™€ Notion ë‚´ìš©ì˜ ë‚ ì§œ ì¼ì¹˜ì„± ê²€ì¦"""

    mcp_dates = extract_date_from_content(mcp_data)
    notion_dates = extract_date_from_content(notion_content)

    # ì–´ì œ ë‚ ì§œ ê³„ì‚°
    yesterday = date.today().strftime('%Y-%m-%d')
    if expected_date:
        yesterday = expected_date

    # ë‚ ì§œ ì¼ì¹˜ì„± í™•ì¸
    mcp_has_expected = any(yesterday in str(mcp_dates) for d in mcp_dates)
    notion_has_expected = any(yesterday in str(notion_dates) for d in notion_dates)

    return {
        "date_consistent": mcp_has_expected and notion_has_expected,
        "expected_date": yesterday,
        "mcp_dates": mcp_dates,
        "notion_dates": notion_dates,
        "mcp_has_expected": mcp_has_expected,
        "notion_has_expected": notion_has_expected
    }

def validate_top10_products(mcp_data: str, notion_content: str) -> Dict:
    """Top 10 ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ì™„ì „ì„± ê²€ì¦"""

    # MCPì—ì„œ Top 10 ìƒí’ˆ ìˆ˜ í™•ì¸
    mcp_top10_pattern = r'(\d+)\.\s*\*\*\[.*?\].*?\*\*.*?GMV.*?(\d+,\d+|\d+).*?ì›'
    mcp_products = re.findall(mcp_top10_pattern, mcp_data)

    # Notionì—ì„œ Top 10 ìƒí’ˆ ìˆ˜ í™•ì¸
    notion_top10_pattern = r'(\d+)\.\s*\*\*\[.*?\].*?\*\*.*?GMV.*?(\d+,\d+|\d+).*?ì›'
    notion_products = re.findall(notion_top10_pattern, notion_content)

    return {
        "top10_complete": len(mcp_products) == len(notion_products) and len(mcp_products) >= 8,
        "mcp_product_count": len(mcp_products),
        "notion_product_count": len(notion_products),
        "minimum_threshold_met": len(notion_products) >= 8
    }

def validate_brand_completeness(mcp_data: str, notion_content: str) -> Dict:
    """ë¸Œëœë“œ ë°ì´í„° ì™„ì „ì„± ê°•í™” ê²€ì¦"""

    # í•„ìˆ˜ ë¸Œëœë“œ ëª©ë¡
    required_brands = ['ë…¸ì–´', 'ë‹¤ë‚˜ì•¤í˜íƒ€', 'ë§ˆì¹˜ë§ˆë¼', 'ë¸Œì—íŠ¸ì™€', 'ì•„ë¥´ì•™', 'ì§€ì¬', 'í¬ì• ']
    optional_brands = ['í€¸ì¦ˆì…€ë ‰ì…˜', 'ë² ë¥´ë‹¤']

    mcp_brands_found = []
    notion_brands_found = []

    for brand in required_brands + optional_brands:
        # MCPì—ì„œ ë¸Œëœë“œ ë°ì´í„° í™•ì¸ (GMV í¬í•¨)
        mcp_pattern = rf'{brand}.*?GMV.*?(\d+,\d+|\d+).*?ì›'
        if re.search(mcp_pattern, mcp_data):
            mcp_brands_found.append(brand)

        # Notionì—ì„œ ë¸Œëœë“œ ë°ì´í„° í™•ì¸
        notion_pattern = rf'\*\*{brand}\*\*.*?GMV.*?(\d+,\d+|\d+).*?ì›'
        if re.search(notion_pattern, notion_content):
            notion_brands_found.append(brand)

    # í•„ìˆ˜ ë¸Œëœë“œ ëˆ„ë½ í™•ì¸
    missing_required = [b for b in required_brands if b not in notion_brands_found]

    return {
        "brands_complete": len(missing_required) == 0,
        "mcp_brands_count": len(mcp_brands_found),
        "notion_brands_count": len(notion_brands_found),
        "required_brands_found": [b for b in required_brands if b in notion_brands_found],
        "missing_required_brands": missing_required,
        "optional_brands_found": [b for b in optional_brands if b in notion_brands_found]
    }

def validate_completeness(mcp_sections: Set[str], notion_sections: Set[str]) -> Dict:
    """ì™„ì „ì„± ê²€ì¦ ë° ê²°ê³¼ ë°˜í™˜"""
    missing_sections = mcp_sections - notion_sections
    extra_sections = notion_sections - mcp_sections

    # í•„ìˆ˜ ì„¹ì…˜ ì •ì˜ (MCPì— ìˆìœ¼ë©´ Notionì—ë„ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•¨)
    critical_sections = {
        "brand_snapshots", "top_performers", "urgent_priorities",
        "action_items", "sufficient_brands"
    }

    missing_critical = missing_sections & critical_sections

    is_complete = len(missing_critical) == 0
    completeness_score = (len(notion_sections) / max(len(mcp_sections), 1)) * 100

    return {
        "is_complete": is_complete,
        "completeness_score": round(completeness_score, 1),
        "missing_sections": list(missing_sections),
        "missing_critical": list(missing_critical),
        "mcp_section_count": len(mcp_sections),
        "notion_section_count": len(notion_sections)
    }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 3:
        print("Usage: python3 notion_content_validator.py <mcp_data_file> <notion_content_file> [expected_date]")
        sys.exit(1)

    mcp_file, notion_file = sys.argv[1], sys.argv[2]
    expected_date = sys.argv[3] if len(sys.argv) > 3 else None

    try:
        # MCP ë°ì´í„° ì½ê¸°
        with open(mcp_file, 'r', encoding='utf-8') as f:
            mcp_data = f.read()

        # Notion ë‚´ìš© ì½ê¸°
        with open(notion_file, 'r', encoding='utf-8') as f:
            notion_content = f.read()

    except FileNotFoundError as e:
        print(f"ERROR: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {e}")
        sys.exit(11)
    except Exception as e:
        print(f"ERROR: íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ - {e}")
        sys.exit(12)

    # ì„¹ì…˜ ì¶”ì¶œ
    mcp_sections = extract_mcp_sections(mcp_data)
    notion_sections = extract_notion_sections(notion_content)

    # ê¸°ë³¸ ì™„ì „ì„± ê²€ì¦
    result = validate_completeness(mcp_sections, notion_sections)

    # ê°•í™”ëœ ê²€ì¦ ì‹¤í–‰
    validation_results = {
        "basic_completeness": result
    }

    # ë‚ ì§œ ì¼ì¹˜ì„± ê²€ì¦
    date_validation = validate_date_consistency(mcp_data, notion_content, expected_date)
    validation_results["date_consistency"] = date_validation

    # Top 10 ìƒí’ˆ ì™„ì „ì„± ê²€ì¦
    top10_validation = validate_top10_products(mcp_data, notion_content)
    validation_results["top10_products"] = top10_validation

    # ë¸Œëœë“œ ë°ì´í„° ì™„ì „ì„± ê²€ì¦
    brand_validation = validate_brand_completeness(mcp_data, notion_content)
    validation_results["brand_completeness"] = brand_validation

    # ì „ì²´ ê²€ì¦ ê²°ê³¼ ê³„ì‚°
    all_validations_passed = (
        result["is_complete"] and
        date_validation["date_consistent"] and
        top10_validation["top10_complete"] and
        brand_validation["brands_complete"]
    )

    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ“Š Notion ë³´ê³ ì„œ ê²€ì¦ ê²°ê³¼")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

    if all_validations_passed:
        print("âœ… PASS: ëª¨ë“  ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤")
        print(f"â€¢ ê¸°ë³¸ ì™„ì „ì„±: {result['completeness_score']}%")
        print(f"â€¢ ë‚ ì§œ ì¼ì¹˜ì„±: âœ… í†µê³¼")
        print(f"â€¢ Top 10 ìƒí’ˆ: {top10_validation['notion_product_count']}ê°œ")
        print(f"â€¢ ë¸Œëœë“œ ë°ì´í„°: {brand_validation['notion_brands_count']}ê°œ ë¸Œëœë“œ")
        sys.exit(0)
    else:
        print("âŒ FAIL: ì¼ë¶€ ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

        # ê¸°ë³¸ ì™„ì „ì„±
        print(f"â€¢ ê¸°ë³¸ ì™„ì „ì„±: {result['completeness_score']}% ({'âœ…' if result['is_complete'] else 'âŒ'})")
        if not result["is_complete"]:
            print(f"  - ëˆ„ë½ëœ í•µì‹¬ ì„¹ì…˜: {result['missing_critical']}")

        # ë‚ ì§œ ì¼ì¹˜ì„±
        print(f"â€¢ ë‚ ì§œ ì¼ì¹˜ì„±: {'âœ…' if date_validation['date_consistent'] else 'âŒ'}")
        if not date_validation["date_consistent"]:
            print(f"  - ì˜ˆìƒ ë‚ ì§œ: {date_validation['expected_date']}")
            print(f"  - MCP ë‚ ì§œ: {date_validation['mcp_dates']}")
            print(f"  - Notion ë‚ ì§œ: {date_validation['notion_dates']}")

        # Top 10 ìƒí’ˆ
        print(f"â€¢ Top 10 ìƒí’ˆ: {'âœ…' if top10_validation['top10_complete'] else 'âŒ'}")
        print(f"  - MCP: {top10_validation['mcp_product_count']}ê°œ")
        print(f"  - Notion: {top10_validation['notion_product_count']}ê°œ")

        # ë¸Œëœë“œ ì™„ì „ì„±
        print(f"â€¢ ë¸Œëœë“œ ì™„ì „ì„±: {'âœ…' if brand_validation['brands_complete'] else 'âŒ'}")
        print(f"  - í•„ìˆ˜ ë¸Œëœë“œ: {len(brand_validation['required_brands_found'])}/7ê°œ")
        if brand_validation['missing_required_brands']:
            print(f"  - ëˆ„ë½ëœ ë¸Œëœë“œ: {brand_validation['missing_required_brands']}")

        sys.exit(13)

if __name__ == "__main__":
    main()